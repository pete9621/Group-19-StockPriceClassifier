{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd309381",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1009ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "CompanyProfiles = pd.read_csv('CompanyProfiles.csv',index_col=\"symbol\",\n",
    "    dtype={\n",
    "        \"row_numbr\":int,\n",
    "        \"price\":str,\n",
    "        \"beta\":str,\n",
    "        \"volAvg\":str,\n",
    "        \"mktCap\":str,\n",
    "        \"lastDiv\":str,\n",
    "        \"range\":str,\n",
    "        \"changes\":str,\n",
    "        \"companyName\":str,\n",
    "        \"currency\":str,\n",
    "        \"cik\":str,\n",
    "        \"isin\":str,\n",
    "        \"cusip\":str,\n",
    "        \"exchange\":str,\n",
    "        \"exchangeShortName\":str,\n",
    "        \"industry\":str,\n",
    "        \"website\":str,\n",
    "        \"description\":str,\n",
    "        \"ceo\":str,\n",
    "        \"sector\":str,\n",
    "        \"country\":str,\n",
    "        \"fullTimeEmployees\":str,\n",
    "        \"phone\":str,\n",
    "        \"address\":str,\n",
    "        \"city\":str,\n",
    "        \"state\":str,\n",
    "        \"zip\":str,0\n",
    "        \"dcfDiff\":str,\n",
    "        \"dcf\":str,\n",
    "        \"image\":str,\n",
    "        \"ipoDate\":str,\n",
    "        \"defaultImage\":bool,\n",
    "        \"isEtf\":bool,\n",
    "        \"isActivelyTrading\":bool,\n",
    "        \"isAdr\":bool,\n",
    "        \"isFund\":bool\n",
    "    })\n",
    "StockPrices = pd.read_csv(\"StockPrices.csv\",index_col=[\"symbol\",\"date\"],parse_dates=[\"date\"],dtype={'date':str,'Unnamed: 0':int,\"symbol\":str,\"close\":float})\n",
    "StockPrices.drop(columns=['Unnamed: 0'],axis=1,inplace=True)\n",
    "CashFlows = pd.read_csv(\"CashFlows.csv\",index_col=[\"symbol\",\"date\"],parse_dates=[\"date\"],\n",
    "    dtype={\n",
    "        \"row_numbr\":int,\n",
    "        \"cik\":float,\n",
    "        \"reportedCurrency\":str,\n",
    "        \"fillingDate\":str,\n",
    "        \"acceptedDate\":str,\n",
    "        \"calendarYear\":float,\n",
    "        \"period\":str,\n",
    "        \"netIncome\":float,\n",
    "        \"depreciationAndAmortization\":float,\n",
    "        \"deferredIncomeTax\":float,\n",
    "        \"stockBasedCompensation\":float,\n",
    "        \"changeInWorkingCapital\":float,\n",
    "        \"accountsReceivables\":float,\n",
    "        \"inventory\":float,\n",
    "        \"accountsPayables\":float,\n",
    "        \"otherWorkingCapital\":float,\n",
    "        \"otherNonCashItems\":float,\n",
    "        \"netCashProvidedByOperatingActivities\":float,\n",
    "        \"investmentsInPropertyPlantAndEquipment\":float,\n",
    "        \"acquisitionsNet\":float,\n",
    "        \"purchasesOfInvestments\":float,\n",
    "        \"salesMaturitiesOfInvestments\":float,\n",
    "        \"otherInvestingActivites\":float,\n",
    "        \"netCashUsedForInvestingActivites\":float,\n",
    "        \"debtRepayment\":float,\n",
    "        \"commonStockIssued\":float,\n",
    "        \"commonStockRepurchased\":float,\n",
    "        \"dividendsPaid\":float,\n",
    "        \"otherFinancingActivites\":float,\n",
    "        \"netCashUsedProvidedByFinancingActivities\":float,\n",
    "        \"effectOfForexChangesOnCash\":float,\n",
    "        \"netChangeInCash\":float,\n",
    "        \"cashAtEndOfPeriod\":float,\n",
    "        \"cashAtBeginningOfPeriod\":float,\n",
    "        \"operatingCashFlow\":float,\n",
    "        \"capitalExpenditure\":float,\n",
    "        \"freeCashFlow\":float,\n",
    "        \"link\":str,\n",
    "        \"finalLink\":str\n",
    "    })\n",
    "IncomeStatements = pd.read_csv(\"IncomeStatements1.csv\",index_col=[\"symbol\",\"date\"],parse_dates=[\"date\"],\n",
    "   dtype={\n",
    "        \"reportedCurrency\":str,\n",
    "        \"cik\":str,\n",
    "        \"fillingDate\":str,\n",
    "        \"acceptedDate\":str,\n",
    "        \"calendarYear\":str,\n",
    "        \"period\":str,\n",
    "        \"revenue\":float,\n",
    "        \"costOfRevenue\":float,\n",
    "        \"grossProfit\":float,\n",
    "        \"grossProfitRatio\":float,\n",
    "        \"researchAndDevelopmentExpenses\":float,\n",
    "        \"generalAndAdministrativeExpenses\":float,\n",
    "        \"sellingAndMarketingExpenses\":float,\n",
    "        \"sellingGeneralAndAdministrativeExpenses\":float,\n",
    "        \"otherExpenses\":float,\n",
    "        \"operatingExpenses\":float,\n",
    "        \"costAndExpenses\":float,\n",
    "        \"interestExpense\":float,\n",
    "        \"depreciationAndAmortization\":float,\n",
    "        \"ebitda\":float,\n",
    "        \"ebitdaratio\":float,\n",
    "        \"operatingIncome\":float,\n",
    "        \"operatingIncomeRatio\":float,\n",
    "        \"totalOtherIncomeExpensesNet\":float,\n",
    "        \"incomeBeforeTax\":float,\n",
    "        \"incomeBeforeTaxRatio\":float,\n",
    "        \"incomeTaxExpense\":float,\n",
    "        \"netIncome\":float,\n",
    "        \"netIncomeRatio\":float,\n",
    "        \"eps\":float,\n",
    "        \"epsdiluted\":float,\n",
    "        \"weightedAverageShsOut\":float,\n",
    "        \"weightedAverageShsOutDil\":float,\n",
    "        \"link\":str,\n",
    "        \"finalLink\":str\n",
    "   })\n",
    "IncomeStatements.drop(columns=['Unnamed: 0'],axis=1,inplace=True)\n",
    "BalanceSheets = pd.read_csv(\"BalanceSheets1.csv\",index_col=[\"symbol\",\"sheet_date\"],parse_dates=[\"sheet_date\"],\n",
    "    dtype={  \n",
    "        \"reportedCurrency\":str,\n",
    "        \"fillingDate\":str,\n",
    "        \"acceptedDate\":str,\n",
    "        \"quarter_period\":str,\n",
    "        \"cashAndCashEquivalents\":float,\n",
    "        \"shortTermInvestments\":float,\n",
    "        \"cashAndShortTermInvestments\":float,\n",
    "        \"netReceivables\":float,\n",
    "        \"inventory\":float,\n",
    "        \"otherCurrentAssets\":float,\n",
    "        \"totalCurrentAssets\":float,\n",
    "        \"propertyPlantEquipmentNet\":float,\n",
    "        \"goodwill\":float,\n",
    "        \"intangibleAssets\":float,\n",
    "        \"goodwillAndIntangibleAssets\":float,\n",
    "        \"longTermInvestments\":float,\n",
    "        \"taxAssets\":float,\n",
    "        \"otherNonCurrentAssets\":float,\n",
    "        \"totalNonCurrentAssets\":float,\n",
    "        \"otherAssets\":float,\n",
    "        \"totalAssets\":float,\n",
    "        \"accountPayables\":float,\n",
    "        \"shortTermDebt\":float,\n",
    "        \"taxPayables\":float,\n",
    "        \"deferredRevenue\":float,\n",
    "        \"otherCurrentLiabilities\":float,\n",
    "        \"totalCurrentLiabilities\":float,\n",
    "        \"longTermDebt\":float,\n",
    "        \"deferredRevenueNonCurrent\":float,\n",
    "        \"deferredTaxLiabilitiesNonCurrent\":float,\n",
    "        \"otherNonCurrentLiabilities\":float,\n",
    "        \"totalNonCurrentLiabilities\":float,\n",
    "        \"otherLiabilities\":float,\n",
    "        \"totalLiabilities\":float,\n",
    "        \"commonStock\":float,\n",
    "        \"retainedEarnings\":float,\n",
    "        \"accumulatedOtherComprehensiveIncomeLoss\":float,\n",
    "        \"othertotalStockholdersEquity\":float,\n",
    "        \"totalStockholdersEquity\":float,\n",
    "        \"totalLiabilitiesAndStockholdersEquity\":float,\n",
    "        \"totalInvestments\":float,\n",
    "        \"totalDebt\":float,\n",
    "        \"netDebt\":float,\n",
    "        \"link\":str,\n",
    "        \"finalLink\":str,\n",
    "        \"cik\":str,\n",
    "        \"calendarYear\":str \n",
    "    })\n",
    "BalanceSheets.drop(columns=['row_numbr'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e3934",
   "metadata": {},
   "source": [
    "# Trim Some Columns We Don't Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of some columns that aren't necessary\n",
    "BalanceSheets.drop(columns=['acceptedDate','fillingDate','quarter_period','link','finalLink','cik','calendarYear'],axis=1,inplace=True)\n",
    "IncomeStatements.drop(columns=[\"cik\",\"fillingDate\",\"acceptedDate\",\"calendarYear\",\"period\",\"link\",\"finalLink\"],axis=1,inplace=True)\n",
    "CashFlows.drop(columns=[\"cik\",\"fillingDate\",\"acceptedDate\",\"calendarYear\",\"period\",\"link\",\"finalLink\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ba720",
   "metadata": {},
   "source": [
    "# Remove Records With Missing Currency Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08153721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop companies with missing currency values\n",
    "CompanyProfiles.dropna(axis=0,subset=[\"currency\"],inplace=True)\n",
    "IncomeStatements.dropna(axis=0,subset=[\"reportedCurrency\"],inplace=True)\n",
    "BalanceSheets.dropna(axis=0,subset=[\"reportedCurrency\"],inplace=True)\n",
    "CashFlows.dropna(axis=0,subset=[\"reportedCurrency\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ca6aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USD' 'EUR' 'CAD' 'CHF' 'RUB' 'INR' 'DKK' 'SEK' 'NOK' 'JPY' 'GBp' 'GBP'\n",
      " 'AUD' 'HKD' 'ILS' 'CNY' 'BRL' 'SGD' 'NZD' 'IDR' 'CLP' 'KRW' 'TRY' 'TWD'\n",
      " 'MXN' 'ZAc' 'ILA' 'PLN' 'THB' 'QAR' nan 'MYR' 'CZK' 'SAR' 'ISK']\n",
      "['USD' 'MXN' 'BRL' 'CNY' 'EUR' 'INR' 'ZAR' 'GBP' 'CAD' 'TWD' 'RUB' 'KRW'\n",
      " 'CHF' 'SEK' 'COP' 'DKK' 'JPY' 'ARS' 'CLP' 'PEN' 'IDR' 'AUD' 'TRY' 'PHP'\n",
      " 'ILS' 'NZD' nan 'HKD' 'MAD' 'ZMW' 'GEL' 'MYR' 'EGP' 'NOK' 'RSD' 'MOP'\n",
      " 'SGD' 'THB' 'BDT' 'SAR' 'PLN' 'QAR' 'ISK']\n",
      "['USD' 'MXN' 'BRL' 'CNY' 'EUR' 'INR' 'ZAR' 'GBP' 'CAD' 'TWD' 'RUB' 'KRW'\n",
      " 'SEK' 'COP' 'DKK' 'JPY' 'ARS' 'CLP' 'PEN' nan 'IDR' 'AUD' 'TRY' 'PHP'\n",
      " 'CHF' 'ILS' 'NZD' 'HKD' 'MAD' 'ZMW' 'GEL' 'MYR' 'EGP' 'NOK' 'RSD' 'MOP'\n",
      " 'SGD' 'THB' 'BDT' 'SAR' 'PLN' 'QAR' 'ISK']\n",
      "['USD' 'MXN' 'BRL' 'CNY' 'EUR' 'INR' 'ZAR' 'GBP' 'CAD' nan 'TWD' 'RUB'\n",
      " 'KRW' 'SEK' 'COP' 'DKK' 'JPY' 'ARS' 'CLP' 'PEN' 'IDR' 'AUD' 'TRY' 'PHP'\n",
      " 'CHF' 'ILS' 'NZD' 'HKD' 'MAD' 'ZMW' 'GEL' 'MYR' 'EGP' 'NOK' 'RSD' 'MOP'\n",
      " 'SGD' 'THB' 'BDT' 'SAR' 'PLN' 'ISK']\n"
     ]
    }
   ],
   "source": [
    "#get list of currencies\n",
    "print(CompanyProfiles[\"currency\"].unique())\n",
    "\n",
    "#Income Statements\n",
    "print(IncomeStatements[\"reportedCurrency\"].unique())\n",
    "\n",
    "#Balance sheets\n",
    "print(BalanceSheets[\"reportedCurrency\"].unique())\n",
    "\n",
    "#CashFlows\n",
    "print(CashFlows[\"reportedCurrency\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d68e73",
   "metadata": {},
   "source": [
    "# Removing Records in Currencies Without Good Exchange Rate Data\n",
    "#### I could not find good data for the following currencies:\n",
    "    [PEN, PHP, GEL, EGP, RSD, MOP, BDT, ZAc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies_to_remove = [\"PEN\", \"PHP\", \"GEL\", \"EGP\", \"RSD\", \"MOP\", \"BDT\", \"ZAc\",\"ILA\"]\n",
    "for currency in currencies_to_remove:\n",
    "    CompanyProfiles = CompanyProfiles[CompanyProfiles['currency'] != currency]\n",
    "\n",
    "for currency in currencies_to_remove:\n",
    "    IncomeStatements = IncomeStatements[IncomeStatements['reportedCurrency'] != currency]\n",
    "    \n",
    "for currency in currencies_to_remove:\n",
    "    BalanceSheets = BalanceSheets[BalanceSheets['reportedCurrency'] != currency]\n",
    "    \n",
    "for currency in currencies_to_remove:\n",
    "    CashFlows = CashFlows[CashFlows['reportedCurrency'] != currency]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d4eee",
   "metadata": {},
   "source": [
    "# Create New Exchange Rate Files with Proper Complete Date Ranges\n",
    "### Also convert non-daily and weekday only data to complete daily data\n",
    "##### For daily data, fill missing data with exchange rate of day before inside csv files. I used excel tools to fix missing data rather than coding it.\n",
    "##### Make the following changes to the data for the groups inside csv files with excel(easier to group by same date ranges):\n",
    "    1. fill empty weekends values with friday's exchange rate.\n",
    "    2. change weekly data to daily data by making each day of the week equal to the value of the week given\n",
    "    3. change monthly data to daily data by making each day of the month equal to the value of the month given\n",
    "    4. change annual data to daily data by making each day of the year equal to the value of the year given (only qatar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4273d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group 1\n",
    "days = pd.date_range(start=\"1/1/1960\",end=\"11/1/2021\")\n",
    "ExchangeRates = pd.DataFrame({},index=days)\n",
    "ExchangeRates.index.rename(\"DATE\",inplace=True)\n",
    "ExchangeRateFiles= [\n",
    "    \"ILStoOneUSDMonthly.csv\", #1/1/1960 - 9/1/2021\n",
    "    \"CLPtoOneUSDmonthly.csv\", #1/1/1960 -9/1/2021\n",
    "    \"PLNtoOneUSDmonthly.csv\", #1/1/1960 - 10/1/2021\n",
    "    \"TRYtoOneUSDmonthly.csv\", #1/1/1960 - 10/1/2021\n",
    "    \"SARtoOneUSDmonthly.csv\", #1/1/1960 - 9/1/2021\n",
    "    \"ISKtoOneUSDmonthly.csv\", #1/1/1960 - 10/1/2021\n",
    "]\n",
    "for file in ExchangeRateFiles:\n",
    "    tempDf = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    ExchangeRates = ExchangeRates.merge(tempDf,\"outer\",\"DATE\")\n",
    "ExchangeRates.sort_index(axis=0,inplace=True)\n",
    "ExchangeRates.to_csv('Group1Aggregate.csv')\n",
    "\n",
    "\n",
    "#group 2\n",
    "days = pd.date_range(start=\"1/4/1971\",end=\"11/26/2021\")\n",
    "ExchangeRates = pd.DataFrame({},index=days)\n",
    "ExchangeRates.index.rename(\"DATE\",inplace=True)\n",
    "ExchangeRateFiles= [\n",
    "    \"CADtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"GBPtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"CHFtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"DKKtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"SEKtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"NOKtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"JPYtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"MYRtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"AUDtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "    \"NZDtoOneUSD.csv\", #1/4/1971 - 11/26/2021\n",
    "]\n",
    "for file in ExchangeRateFiles:\n",
    "    tempDf = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    ExchangeRates = ExchangeRates.merge(tempDf,\"outer\",\"DATE\")\n",
    "ExchangeRates.sort_index(axis=0,inplace=True)\n",
    "ExchangeRates.to_csv('Group2Aggregate.csv')\n",
    "\n",
    "#group 3\n",
    "days = pd.date_range(start=\"1/4/1981\",end=\"11/26/2021\")\n",
    "ExchangeRates = pd.DataFrame({},index=days)\n",
    "ExchangeRates.index.rename(\"DATE\",inplace=True)\n",
    "ExchangeRateFiles= [\n",
    "    \"HKDtoOneUSD.csv\", #1/2/1981 - 11/26/2021\n",
    "    \"SGDtoOneUSD.csv\", #1/2/1981 - 11/26/2021\n",
    "    \"THBtoOneUSD.csv\", #1/2/1981 - 11/26/2021\n",
    "]\n",
    "for file in ExchangeRateFiles:\n",
    "    tempDf = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    ExchangeRates = ExchangeRates.merge(tempDf,\"outer\",\"DATE\")\n",
    "ExchangeRates.sort_index(axis=0,inplace=True)\n",
    "ExchangeRates.to_csv('Group3Aggregate.csv')\n",
    "\n",
    "#individual files. I need to make copy of files with all dates in their range, \n",
    "    #because they don't list many of the dates they don't have. \n",
    "    #We need to fill those dates with exchange rates based on the exchange rates near them.\n",
    "  \n",
    "individualFiles = [\"ZMWtoOneUSDAnnual.csv\",\n",
    "    \"MADtoOneUSDAnnual.csv\",\n",
    "    \"ARStoOneUSDMonthly.csv\",\n",
    "    \"COPtoOneUSDMonthly.csv\",\n",
    "    \"QARtoOneUSDannual.csv\", #1/1/1966-1/1/2020\n",
    "    \"IDRtoOneUSDmonthly.csv\", #1/1/1967 - 9/1/2021\n",
    "    \"INRtoOneUSD.csv\", #1/2/1973 - 11/26/2021\n",
    "    \"ZACtoOneUSD.csv\", #1/2/1980 - 11/26/2021\n",
    "    \"CNYtoOneUSDweekly.csv\", #1/10/1981 - 11/27/2021\n",
    "    \"KRWtoOneUSD.csv\", #4/13/1981 - 11/26/2021\n",
    "    \"TWDtoOneUSD.csv\", #10/3/1983 - 11/26/2021\n",
    "    \"CZKtoOneUSD.csv\", #1/1/1991 - 10/1/2021\n",
    "    \"RUBtoOneUSDMonthly.csv\", #6/1/1992 - 9/1/2021\n",
    "    \"MXNtoOneUSD.csv\", #11/8/1993 - 11/26/2021\n",
    "    \"BRLtoOneUSD.csv\", #1/2/1995 - 11/26/2021\n",
    "    \"EURtoOneUSD.csv\"] # 1/4/1999 - 11/26/2021 \n",
    "\n",
    "\n",
    "for file in individualFiles:\n",
    "    tempDf = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    days = pd.date_range(start=tempDf.index.values[0],end=tempDf.index.values[-1])\n",
    "    ExchangeRates = pd.DataFrame({},index=days)\n",
    "    ExchangeRates.index.rename(\"DATE\",inplace=True)\n",
    "    ExchangeRates = ExchangeRates.merge(tempDf,\"outer\",\"DATE\")\n",
    "    ExchangeRates.to_csv(file.split(\".\")[0]+\"_new.csv\")\n",
    "    \n",
    "individualFiles = [\"ZMWtoOneUSDAnnual.csv\",\n",
    "    \"MADtoOneUSDAnnual.csv\",\n",
    "    \"ARStoOneUSDMonthly.csv\",\n",
    "    \"COPtoOneUSDMonthly.csv\"]\n",
    "for file in individualFiles:\n",
    "    tempDf = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    days = pd.date_range(start=tempDf.index.values[0],end=tempDf.index.values[-1])\n",
    "    ExchangeRates = pd.DataFrame({},index=days)\n",
    "    ExchangeRates.index.rename(\"DATE\",inplace=True)\n",
    "    ExchangeRates = ExchangeRates.merge(tempDf,\"outer\",\"DATE\")\n",
    "    ExchangeRates.to_csv(file.split(\".\")[0]+\"_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569764ac",
   "metadata": {},
   "source": [
    "# Collect and Merge the Edited CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee880819",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = pd.date_range(start=\"1/1/1960\",end=\"11/26/2021\")\n",
    "ExchangeRates = pd.DataFrame({},index=days)\n",
    "ExchangeRates.index.rename(\"DATE\",inplace=True)\n",
    "ExchangeRateFiles= [\"BRLtoOneUSD_new.csv\",\n",
    "    \"EURtoOneUSD_new.csv\",\n",
    "    \"CZKtoOneUSD_new.csv\",\n",
    "    \"MXNtoOneUSD_new.csv\",\n",
    "    \"RUBtoOneUSDMonthly_new.csv\",\n",
    "    \"TWDtoOneUSD_new.csv\",\n",
    "    \"CNYtoOneUSDweekly_new.csv\",\n",
    "    \"KRWtoOneUSD_new.csv\",\n",
    "    \"ZACtoOneUSD_new.csv\",\n",
    "    \"INRtoOneUSD_new.csv\",\n",
    "    \"ZMWtoOneUSDAnnual_new.csv\",\n",
    "    \"MADtoOneUSDAnnual_new.csv\",\n",
    "    \"ARStoOneUSDMonthly_new.csv\",\n",
    "    \"COPtoOneUSDMonthly_new.csv\",                          \n",
    "    \"Group3Aggregate.csv\",\n",
    "    \"IDRtoOneUSDmonthly_new.csv\",\n",
    "    \"QARtoOneUSDannual_new.csv\",\n",
    "    \"Group2Aggregate.csv\",\n",
    "    \"Group1Aggregate.csv\"]\n",
    "for file in ExchangeRateFiles:\n",
    "    tempDf = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    ExchangeRates = ExchangeRates.merge(tempDf,\"outer\",\"DATE\")\n",
    "ExchangeRates.sort_index(axis=0,inplace=True)\n",
    "ExchangeRates.to_csv('ExchangeRateAggregate.csv')\n",
    "\n",
    "#manually add the following to the ExchangeRateAggregate.csv\n",
    "#ILA is just ILS*100\n",
    "#GBp is GBP*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6779b",
   "metadata": {},
   "source": [
    "# Shrink Data By Removing Any Missing Companies Accross Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The only companies whose stock information we care about remain in all our datasets. We can eliminate data that correspond to companies not in this table.\n",
    "\n",
    "#stock prices\n",
    "#temp DF to merge to get rid of symbols not wanted. This is an efficient way to eliminate symbols not wanted\n",
    "tempStockPricesEmptyDf = pd.DataFrame({},index=StockPrices.index.get_level_values(0).unique())\n",
    "tempStockPricesEmptyDf.index.rename(\"symbol\",inplace=True)\n",
    "\n",
    "CompanyProfiles = CompanyProfiles.join(tempStockPricesEmptyDf,how=\"inner\")\n",
    "CashFlows = CashFlows.join(tempStockPricesEmptyDf,how=\"inner\")\n",
    "IncomeStatements = IncomeStatements.join(tempStockPricesEmptyDf,how=\"inner\")\n",
    "BalanceSheets = BalanceSheets.join(tempStockPricesEmptyDf,how=\"inner\")\n",
    "\n",
    "#companyProfiles\n",
    "tempCompanyProfileEmptyDf = pd.DataFrame({},index=CompanyProfiles.index.values)\n",
    "tempCompanyProfileEmptyDf.index.rename(\"symbol\",inplace=True)\n",
    "\n",
    "CashFlows = CashFlows.join(tempCompanyProfileEmptyDf,how=\"inner\")\n",
    "StockPrices = StockPrices.join(tempCompanyProfileEmptyDf,how=\"inner\")\n",
    "IncomeStatements = IncomeStatements.join(tempCompanyProfileEmptyDf,how=\"inner\")\n",
    "BalanceSheets = BalanceSheets.join(tempCompanyProfileEmptyDf,how=\"inner\")\n",
    "\n",
    "\n",
    "#CashFlows\n",
    "tempDf = pd.DataFrame({},CashFlows.index.get_level_values(0).unique())\n",
    "tempDf.index.rename(\"symbol\",inplace=True)\n",
    "\n",
    "CompanyProfiles = CompanyProfiles.join(tempDf,how=\"inner\")\n",
    "StockPrices = StockPrices.join(tempDf,how=\"inner\")\n",
    "IncomeStatements = IncomeStatements.join(tempDf,how=\"inner\")\n",
    "BalanceSheets = BalanceSheets.join(tempDf,how=\"inner\")\n",
    "\n",
    "#BalanceSheets\n",
    "tempDf = pd.DataFrame({},BalanceSheets.index.get_level_values(0).unique())\n",
    "tempDf.index.rename(\"symbol\",inplace=True)\n",
    "\n",
    "CompanyProfiles = CompanyProfiles.join(tempDf,how=\"inner\")\n",
    "StockPrices = StockPrices.join(tempDf,how=\"inner\")\n",
    "IncomeStatements = IncomeStatements.join(tempDf,how=\"inner\")\n",
    "CashFlows = CashFlows.join(tempDf,how=\"inner\")\n",
    "\n",
    "#IncomeStatements\n",
    "tempDf = pd.DataFrame({},IncomeStatements.index.get_level_values(0).unique())\n",
    "tempDf.index.rename(\"symbol\",inplace=True)\n",
    "\n",
    "CompanyProfiles = CompanyProfiles.join(tempDf,how=\"inner\")\n",
    "StockPrices = StockPrices.join(tempDf,how=\"inner\")\n",
    "BalanceSheets = BalanceSheets.join(tempDf,how=\"inner\")\n",
    "CashFlows = CashFlows.join(tempDf,how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a61fd1",
   "metadata": {},
   "source": [
    "### Remove Duplicates values in index, which should not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CashFlows = CashFlows[~CashFlows.index.duplicated()]\n",
    "StockPrices = StockPrices[~StockPrices.index.duplicated()]\n",
    "IncomeStatements = IncomeStatements[~IncomeStatements.index.duplicated()]\n",
    "BalanceSheets = BalanceSheets[~BalanceSheets.index.duplicated()]\n",
    "CompanyProfiles = CompanyProfiles[~CompanyProfiles.index.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a33392",
   "metadata": {},
   "source": [
    "# Applying Exchange Rates and Save Converted Files\n",
    "##### Converting all StockPrices, CashFlows, IncomeStatements, and BalanceSheets monetary information to USD equivalent using historical exchange rates. Drop any records without a corresponding exchange rate entry. We need to make this conversion to stock for purchasing advisement effects. We need to convert the rest of the data, because many companies switch their reported currencies over time. \n",
    "\n",
    "##### Company Profiles have the currency for the stock data, but other data has the reported currency for their data contained within the tables. These currencies may differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a very long time to run\n",
    "#stock Prices\n",
    "a = StockPrices.index.get_level_values(0).unique().values.tolist()\n",
    "b = CompanyProfiles.index.values.tolist()\n",
    "\n",
    "def inner_join(a,b):\n",
    "    result = []\n",
    "    for value in a:\n",
    "        if value in b:\n",
    "            result.append(value)\n",
    "    return result\n",
    "\n",
    "def convert(col,currency):\n",
    "    if col.dtype == float:\n",
    "        return col.div(ExchangeRates[currency].reindex(col.index))\n",
    "    if col.name == \"reportedCurrency\":\n",
    "        return \"USD\"\n",
    "    return col\n",
    "\n",
    "symbols = inner_join(a,b)\n",
    "for symbol in symbols:\n",
    "    currency = CompanyProfiles.at[symbol,\"currency\"]\n",
    "    if currency != 'USD':\n",
    "        StockPrices.loc[symbol] = StockPrices.loc[symbol].apply(convert,axis=0,currency=currency).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "StockPrices.to_csv(\"ConvertedStockPrices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 2hr + to run\n",
    "#IncomeStatements\n",
    "def convertByRow(row,length):\n",
    "    if row[\"reportedCurrency\"] != 'USD':\n",
    "        row = row.apply(valueConvert ,convert_dtype=False,currency=row[\"reportedCurrency\"],date=row.name[1])\n",
    "        row[\"reportedCurrency\"] = 'USD'\n",
    "    return row   \n",
    "def valueConvert(item,currency,date):\n",
    "    if type(item) == float:\n",
    "        return item/ExchangeRates.at[date,currency]\n",
    "    return item\n",
    "                \n",
    "\n",
    "symbols = IncomeStatements.index.get_level_values(0).unique()\n",
    "length = IncomeStatements.shape[1]\n",
    "IncomeStatements = IncomeStatements.apply(convertByRow,axis=1,length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530aeb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomeStatements.to_csv(\"ConvertedIncomeStatements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 30+ min to run\n",
    "#BalanceSheets\n",
    "symbols = BalanceSheets.index.get_level_values(0).unique()\n",
    "length = BalanceSheets.shape[1]\n",
    "BalanceSheets = BalanceSheets.apply(convertByRow,axis=1,length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "BalanceSheets.to_csv(\"ConvertedBalanceSheets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeebaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 30+ min to run\n",
    "#CashFlows\n",
    "symbols = CashFlows.index.get_level_values(0).unique()\n",
    "length = CashFlows.shape[1]\n",
    "CashFlows = CashFlows.apply(convertByRow,axis=1,length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CashFlows.to_csv(\"ConvertedCashFlows.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
