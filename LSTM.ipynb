{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41bd5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "CombinedDataFrame = pd.read_csv(\"CombinedDataFrame.csv\",index_col=[\"symbol\",\"date\"],parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f9cbd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deferredIncomeTax</th>\n",
       "      <th>stockBasedCompensation</th>\n",
       "      <th>changeInWorkingCapital</th>\n",
       "      <th>accountsReceivables</th>\n",
       "      <th>netCashProvidedByOperatingActivities</th>\n",
       "      <th>acquisitionsNet</th>\n",
       "      <th>otherInvestingActivites</th>\n",
       "      <th>commonStockIssued</th>\n",
       "      <th>commonStockRepurchased</th>\n",
       "      <th>effectOfForexChangesOnCash</th>\n",
       "      <th>...</th>\n",
       "      <th>intangibleAssets</th>\n",
       "      <th>longTermInvestments</th>\n",
       "      <th>taxAssets</th>\n",
       "      <th>accountPayables</th>\n",
       "      <th>longTermDebt</th>\n",
       "      <th>deferredRevenueNonCurrent</th>\n",
       "      <th>otherNonCurrentLiabilities</th>\n",
       "      <th>commonStock</th>\n",
       "      <th>totalDebt</th>\n",
       "      <th>is_above_market_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.00000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "      <td>430057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>880.259842</td>\n",
       "      <td>491.140672</td>\n",
       "      <td>2299.106035</td>\n",
       "      <td>906.217639</td>\n",
       "      <td>2381.315051</td>\n",
       "      <td>579.59361</td>\n",
       "      <td>1826.333102</td>\n",
       "      <td>336.959364</td>\n",
       "      <td>967.031959</td>\n",
       "      <td>870.554333</td>\n",
       "      <td>...</td>\n",
       "      <td>726.824574</td>\n",
       "      <td>381.507509</td>\n",
       "      <td>234.996975</td>\n",
       "      <td>1742.736498</td>\n",
       "      <td>1229.518331</td>\n",
       "      <td>36.702670</td>\n",
       "      <td>1549.195279</td>\n",
       "      <td>1243.181264</td>\n",
       "      <td>1745.609861</td>\n",
       "      <td>0.498908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>334.841560</td>\n",
       "      <td>634.403386</td>\n",
       "      <td>1272.027204</td>\n",
       "      <td>287.708273</td>\n",
       "      <td>1377.066774</td>\n",
       "      <td>122.52303</td>\n",
       "      <td>848.076355</td>\n",
       "      <td>417.983060</td>\n",
       "      <td>270.941076</td>\n",
       "      <td>308.362318</td>\n",
       "      <td>...</td>\n",
       "      <td>878.583678</td>\n",
       "      <td>505.292430</td>\n",
       "      <td>428.730690</td>\n",
       "      <td>1336.956245</td>\n",
       "      <td>1157.685458</td>\n",
       "      <td>113.785614</td>\n",
       "      <td>1141.413910</td>\n",
       "      <td>1078.506532</td>\n",
       "      <td>1341.493777</td>\n",
       "      <td>0.499999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>849.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>615.00000</td>\n",
       "      <td>1233.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>849.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>2362.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>2323.000000</td>\n",
       "      <td>615.00000</td>\n",
       "      <td>2057.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1299.000000</td>\n",
       "      <td>1070.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>849.000000</td>\n",
       "      <td>913.000000</td>\n",
       "      <td>3341.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>3573.000000</td>\n",
       "      <td>615.00000</td>\n",
       "      <td>2291.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1442.000000</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>2154.000000</td>\n",
       "      <td>2923.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1853.000000</td>\n",
       "      <td>2066.000000</td>\n",
       "      <td>4588.000000</td>\n",
       "      <td>1692.000000</td>\n",
       "      <td>4822.000000</td>\n",
       "      <td>803.00000</td>\n",
       "      <td>3443.000000</td>\n",
       "      <td>1581.000000</td>\n",
       "      <td>1136.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2691.000000</td>\n",
       "      <td>1811.000000</td>\n",
       "      <td>1530.000000</td>\n",
       "      <td>4165.000000</td>\n",
       "      <td>3493.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>3798.000000</td>\n",
       "      <td>3386.000000</td>\n",
       "      <td>4172.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       deferredIncomeTax  stockBasedCompensation  changeInWorkingCapital  \\\n",
       "count      430057.000000           430057.000000           430057.000000   \n",
       "mean          880.259842              491.140672             2299.106035   \n",
       "std           334.841560              634.403386             1272.027204   \n",
       "min             0.000000                0.000000                0.000000   \n",
       "25%           849.000000               56.000000             1250.000000   \n",
       "50%           849.000000               56.000000             2362.000000   \n",
       "75%           849.000000              913.000000             3341.000000   \n",
       "max          1853.000000             2066.000000             4588.000000   \n",
       "\n",
       "       accountsReceivables  netCashProvidedByOperatingActivities  \\\n",
       "count        430057.000000                         430057.000000   \n",
       "mean            906.217639                           2381.315051   \n",
       "std             287.708273                           1377.066774   \n",
       "min               0.000000                              0.000000   \n",
       "25%             937.000000                           1236.000000   \n",
       "50%             937.000000                           2323.000000   \n",
       "75%             937.000000                           3573.000000   \n",
       "max            1692.000000                           4822.000000   \n",
       "\n",
       "       acquisitionsNet  otherInvestingActivites  commonStockIssued  \\\n",
       "count     430057.00000            430057.000000      430057.000000   \n",
       "mean         579.59361              1826.333102         336.959364   \n",
       "std          122.52303               848.076355         417.983060   \n",
       "min            0.00000                 0.000000           0.000000   \n",
       "25%          615.00000              1233.000000         100.000000   \n",
       "50%          615.00000              2057.000000         100.000000   \n",
       "75%          615.00000              2291.000000         441.000000   \n",
       "max          803.00000              3443.000000        1581.000000   \n",
       "\n",
       "       commonStockRepurchased  effectOfForexChangesOnCash  ...  \\\n",
       "count           430057.000000               430057.000000  ...   \n",
       "mean               967.031959                  870.554333  ...   \n",
       "std                270.941076                  308.362318  ...   \n",
       "min                  0.000000                    0.000000  ...   \n",
       "25%               1089.000000                  876.000000  ...   \n",
       "50%               1089.000000                  876.000000  ...   \n",
       "75%               1089.000000                  876.000000  ...   \n",
       "max               1136.000000                 1718.000000  ...   \n",
       "\n",
       "       intangibleAssets  longTermInvestments      taxAssets  accountPayables  \\\n",
       "count     430057.000000        430057.000000  430057.000000    430057.000000   \n",
       "mean         726.824574           381.507509     234.996975      1742.736498   \n",
       "std          878.583678           505.292430     428.730690      1336.956245   \n",
       "min            0.000000             0.000000       0.000000         0.000000   \n",
       "25%            3.000000            83.000000       1.000000       455.000000   \n",
       "50%          205.000000            83.000000       1.000000      1666.000000   \n",
       "75%         1442.000000           562.000000     281.000000      2916.000000   \n",
       "max         2691.000000          1811.000000    1530.000000      4165.000000   \n",
       "\n",
       "        longTermDebt  deferredRevenueNonCurrent  otherNonCurrentLiabilities  \\\n",
       "count  430057.000000              430057.000000               430057.000000   \n",
       "mean     1229.518331                  36.702670                 1549.195279   \n",
       "std      1157.685458                 113.785614                 1141.413910   \n",
       "min         0.000000                   0.000000                    0.000000   \n",
       "25%         1.000000                   1.000000                  425.000000   \n",
       "50%      1010.000000                   1.000000                 1299.000000   \n",
       "75%      2244.000000                   1.000000                 2549.000000   \n",
       "max      3493.000000                 598.000000                 3798.000000   \n",
       "\n",
       "         commonStock      totalDebt  is_above_market_average  \n",
       "count  430057.000000  430057.000000            430057.000000  \n",
       "mean     1243.181264    1745.609861                 0.498908  \n",
       "std      1078.506532    1341.493777                 0.499999  \n",
       "min         0.000000       0.000000                 0.000000  \n",
       "25%       198.000000     439.000000                 0.000000  \n",
       "50%      1070.000000    1674.000000                 0.000000  \n",
       "75%      2154.000000    2923.000000                 1.000000  \n",
       "max      3386.000000    4172.000000                 1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CombinedDataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10accc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(CombinedDataFrame.drop(columns=\"is_above_market_average\"), \n",
    "                                                    CombinedDataFrame[\"is_above_market_average\"],test_size=0.10, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8a2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy for k-nn is 0.5205087662186672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# knn = KNeighborsClassifier(n_neighbors=10)\n",
    "# knn.fit(X_train, y_train)\n",
    "# knn_pred = knn.predict(X_test)\n",
    "# print (f\" Accuracy for k-nn is {accuracy_score(y_test, knn_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425cc430",
   "metadata": {},
   "source": [
    "# LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "037f17b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.996762   0.994676   0.010462   0.553783   0.992325   0.367372   \n",
      "2   0.998381   0.995160   0.675894   0.553783   0.994192   0.083437   \n",
      "3   0.894226   0.995644   0.976242   0.553783   0.994400   0.112080   \n",
      "4   0.010793   0.993708   0.058631   0.553783   0.990458   0.115816   \n",
      "5   0.024285   0.994676   0.015693   0.553783   0.990666   0.070984   \n",
      "\n",
      "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...  var24(t)  var25(t)  \\\n",
      "1   0.012199   0.063251   0.958627    0.157159  ...       1.0  0.919934   \n",
      "2   0.012199   0.063251   0.958627    0.945285  ...       1.0  0.914964   \n",
      "3   0.013360   0.063251   0.958627    0.048312  ...       1.0  0.914412   \n",
      "4   0.009875   0.063251   0.958627    0.075669  ...       1.0  0.908338   \n",
      "5   0.011037   0.063251   0.958627    0.982538  ...       1.0  0.909994   \n",
      "\n",
      "   var26(t)  var27(t)  var28(t)  var29(t)  var30(t)  var31(t)  var32(t)  \\\n",
      "1  0.000654  0.985834  0.992843  0.001672  0.993154  0.691967  0.991131   \n",
      "2  0.000654  0.985114  0.993129  0.001672  0.993154  0.691967  0.991611   \n",
      "3  0.000654  0.985354  0.993129  0.001672  0.992364  0.689900  0.991611   \n",
      "4  0.000654  0.984874  0.993129  0.001672  0.991838  0.689900  0.991611   \n",
      "5  0.000654  0.984154  0.993129  0.001672  0.992101  0.689900  0.991611   \n",
      "\n",
      "   var33(t)  \n",
      "1       1.0  \n",
      "2       1.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "5       1.0  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 430056 entries, 1 to 430056\n",
      "Data columns (total 65 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   var1(t-1)   430056 non-null  float32\n",
      " 1   var2(t-1)   430056 non-null  float32\n",
      " 2   var3(t-1)   430056 non-null  float32\n",
      " 3   var4(t-1)   430056 non-null  float32\n",
      " 4   var5(t-1)   430056 non-null  float32\n",
      " 5   var6(t-1)   430056 non-null  float32\n",
      " 6   var7(t-1)   430056 non-null  float32\n",
      " 7   var8(t-1)   430056 non-null  float32\n",
      " 8   var9(t-1)   430056 non-null  float32\n",
      " 9   var10(t-1)  430056 non-null  float32\n",
      " 10  var11(t-1)  430056 non-null  float32\n",
      " 11  var12(t-1)  430056 non-null  float32\n",
      " 12  var13(t-1)  430056 non-null  float32\n",
      " 13  var14(t-1)  430056 non-null  float32\n",
      " 14  var15(t-1)  430056 non-null  float32\n",
      " 15  var16(t-1)  430056 non-null  float32\n",
      " 16  var17(t-1)  430056 non-null  float32\n",
      " 17  var18(t-1)  430056 non-null  float32\n",
      " 18  var19(t-1)  430056 non-null  float32\n",
      " 19  var20(t-1)  430056 non-null  float32\n",
      " 20  var21(t-1)  430056 non-null  float32\n",
      " 21  var22(t-1)  430056 non-null  float32\n",
      " 22  var23(t-1)  430056 non-null  float32\n",
      " 23  var24(t-1)  430056 non-null  float32\n",
      " 24  var25(t-1)  430056 non-null  float32\n",
      " 25  var26(t-1)  430056 non-null  float32\n",
      " 26  var27(t-1)  430056 non-null  float32\n",
      " 27  var28(t-1)  430056 non-null  float32\n",
      " 28  var29(t-1)  430056 non-null  float32\n",
      " 29  var30(t-1)  430056 non-null  float32\n",
      " 30  var31(t-1)  430056 non-null  float32\n",
      " 31  var32(t-1)  430056 non-null  float32\n",
      " 32  var1(t)     430056 non-null  float32\n",
      " 33  var2(t)     430056 non-null  float32\n",
      " 34  var3(t)     430056 non-null  float32\n",
      " 35  var4(t)     430056 non-null  float32\n",
      " 36  var5(t)     430056 non-null  float32\n",
      " 37  var6(t)     430056 non-null  float32\n",
      " 38  var7(t)     430056 non-null  float32\n",
      " 39  var8(t)     430056 non-null  float32\n",
      " 40  var9(t)     430056 non-null  float32\n",
      " 41  var10(t)    430056 non-null  float32\n",
      " 42  var11(t)    430056 non-null  float32\n",
      " 43  var12(t)    430056 non-null  float32\n",
      " 44  var13(t)    430056 non-null  float32\n",
      " 45  var14(t)    430056 non-null  float32\n",
      " 46  var15(t)    430056 non-null  float32\n",
      " 47  var16(t)    430056 non-null  float32\n",
      " 48  var17(t)    430056 non-null  float32\n",
      " 49  var18(t)    430056 non-null  float32\n",
      " 50  var19(t)    430056 non-null  float32\n",
      " 51  var20(t)    430056 non-null  float32\n",
      " 52  var21(t)    430056 non-null  float32\n",
      " 53  var22(t)    430056 non-null  float32\n",
      " 54  var23(t)    430056 non-null  float32\n",
      " 55  var24(t)    430056 non-null  float32\n",
      " 56  var25(t)    430056 non-null  float32\n",
      " 57  var26(t)    430056 non-null  float32\n",
      " 58  var27(t)    430056 non-null  float32\n",
      " 59  var28(t)    430056 non-null  float32\n",
      " 60  var29(t)    430056 non-null  float32\n",
      " 61  var30(t)    430056 non-null  float32\n",
      " 62  var31(t)    430056 non-null  float32\n",
      " 63  var32(t)    430056 non-null  float32\n",
      " 64  var33(t)    430056 non-null  float32\n",
      "dtypes: float32(65)\n",
      "memory usage: 109.9 MB\n"
     ]
    }
   ],
   "source": [
    "# prepare data for lstm\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('CombinedDataFrame.csv',index_col=[\"symbol\",\"date\"],parse_dates=[\"date\"])\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[32]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "reframed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87140561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1, 64) (8760,) (421296, 1, 64) (421296,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b7ceff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 - 4s - loss: 0.4910 - val_loss: 0.4913 - 4s/epoch - 35ms/step\n",
      "Epoch 2/50\n",
      "122/122 - 3s - loss: 0.4729 - val_loss: 0.4926 - 3s/epoch - 27ms/step\n",
      "Epoch 3/50\n",
      "122/122 - 4s - loss: 0.4722 - val_loss: 0.4928 - 4s/epoch - 29ms/step\n",
      "Epoch 4/50\n",
      "122/122 - 4s - loss: 0.4693 - val_loss: 0.4924 - 4s/epoch - 29ms/step\n",
      "Epoch 5/50\n",
      "122/122 - 3s - loss: 0.4682 - val_loss: 0.4920 - 3s/epoch - 27ms/step\n",
      "Epoch 6/50\n",
      "122/122 - 3s - loss: 0.4675 - val_loss: 0.4918 - 3s/epoch - 27ms/step\n",
      "Epoch 7/50\n",
      "122/122 - 3s - loss: 0.4670 - val_loss: 0.4909 - 3s/epoch - 25ms/step\n",
      "Epoch 8/50\n",
      "122/122 - 3s - loss: 0.4664 - val_loss: 0.4906 - 3s/epoch - 26ms/step\n",
      "Epoch 9/50\n",
      "122/122 - 3s - loss: 0.4658 - val_loss: 0.4903 - 3s/epoch - 25ms/step\n",
      "Epoch 10/50\n",
      "122/122 - 3s - loss: 0.4654 - val_loss: 0.4888 - 3s/epoch - 25ms/step\n",
      "Epoch 11/50\n",
      "122/122 - 3s - loss: 0.4652 - val_loss: 0.4888 - 3s/epoch - 26ms/step\n",
      "Epoch 12/50\n",
      "122/122 - 3s - loss: 0.4644 - val_loss: 0.4876 - 3s/epoch - 25ms/step\n",
      "Epoch 13/50\n",
      "122/122 - 3s - loss: 0.4634 - val_loss: 0.4866 - 3s/epoch - 25ms/step\n",
      "Epoch 14/50\n",
      "122/122 - 3s - loss: 0.4627 - val_loss: 0.4852 - 3s/epoch - 25ms/step\n",
      "Epoch 15/50\n",
      "122/122 - 3s - loss: 0.4610 - val_loss: 0.4845 - 3s/epoch - 26ms/step\n",
      "Epoch 16/50\n",
      "122/122 - 3s - loss: 0.4602 - val_loss: 0.4843 - 3s/epoch - 25ms/step\n",
      "Epoch 17/50\n",
      "122/122 - 3s - loss: 0.4587 - val_loss: 0.4832 - 3s/epoch - 25ms/step\n",
      "Epoch 18/50\n",
      "122/122 - 3s - loss: 0.4576 - val_loss: 0.4829 - 3s/epoch - 26ms/step\n",
      "Epoch 19/50\n",
      "122/122 - 3s - loss: 0.4564 - val_loss: 0.4820 - 3s/epoch - 25ms/step\n",
      "Epoch 20/50\n",
      "122/122 - 3s - loss: 0.4559 - val_loss: 0.4821 - 3s/epoch - 25ms/step\n",
      "Epoch 21/50\n",
      "122/122 - 3s - loss: 0.4542 - val_loss: 0.4823 - 3s/epoch - 25ms/step\n",
      "Epoch 22/50\n",
      "122/122 - 3s - loss: 0.4532 - val_loss: 0.4825 - 3s/epoch - 25ms/step\n",
      "Epoch 23/50\n",
      "122/122 - 3s - loss: 0.4519 - val_loss: 0.4835 - 3s/epoch - 25ms/step\n",
      "Epoch 24/50\n",
      "122/122 - 3s - loss: 0.4512 - val_loss: 0.4825 - 3s/epoch - 25ms/step\n",
      "Epoch 25/50\n",
      "122/122 - 3s - loss: 0.4505 - val_loss: 0.4830 - 3s/epoch - 25ms/step\n",
      "Epoch 26/50\n",
      "122/122 - 3s - loss: 0.4494 - val_loss: 0.4833 - 3s/epoch - 25ms/step\n",
      "Epoch 27/50\n",
      "122/122 - 3s - loss: 0.4488 - val_loss: 0.4836 - 3s/epoch - 25ms/step\n",
      "Epoch 28/50\n",
      "122/122 - 3s - loss: 0.4478 - val_loss: 0.4857 - 3s/epoch - 25ms/step\n",
      "Epoch 29/50\n",
      "122/122 - 3s - loss: 0.4479 - val_loss: 0.4844 - 3s/epoch - 25ms/step\n",
      "Epoch 30/50\n",
      "122/122 - 3s - loss: 0.4465 - val_loss: 0.4843 - 3s/epoch - 25ms/step\n",
      "Epoch 31/50\n",
      "122/122 - 3s - loss: 0.4457 - val_loss: 0.4843 - 3s/epoch - 25ms/step\n",
      "Epoch 32/50\n",
      "122/122 - 3s - loss: 0.4453 - val_loss: 0.4845 - 3s/epoch - 25ms/step\n",
      "Epoch 33/50\n",
      "122/122 - 3s - loss: 0.4441 - val_loss: 0.4852 - 3s/epoch - 25ms/step\n",
      "Epoch 34/50\n",
      "122/122 - 3s - loss: 0.4436 - val_loss: 0.4853 - 3s/epoch - 25ms/step\n",
      "Epoch 35/50\n",
      "122/122 - 3s - loss: 0.4427 - val_loss: 0.4855 - 3s/epoch - 25ms/step\n",
      "Epoch 36/50\n",
      "122/122 - 3s - loss: 0.4417 - val_loss: 0.4857 - 3s/epoch - 25ms/step\n",
      "Epoch 37/50\n",
      "122/122 - 3s - loss: 0.4409 - val_loss: 0.4872 - 3s/epoch - 25ms/step\n",
      "Epoch 38/50\n",
      "122/122 - 3s - loss: 0.4417 - val_loss: 0.4856 - 3s/epoch - 25ms/step\n",
      "Epoch 39/50\n",
      "122/122 - 3s - loss: 0.4416 - val_loss: 0.4866 - 3s/epoch - 25ms/step\n",
      "Epoch 40/50\n",
      "122/122 - 3s - loss: 0.4414 - val_loss: 0.4867 - 3s/epoch - 25ms/step\n",
      "Epoch 41/50\n",
      "122/122 - 3s - loss: 0.4397 - val_loss: 0.4859 - 3s/epoch - 25ms/step\n",
      "Epoch 42/50\n",
      "122/122 - 3s - loss: 0.4377 - val_loss: 0.4856 - 3s/epoch - 25ms/step\n",
      "Epoch 43/50\n",
      "122/122 - 3s - loss: 0.4365 - val_loss: 0.4866 - 3s/epoch - 25ms/step\n",
      "Epoch 44/50\n",
      "122/122 - 3s - loss: 0.4366 - val_loss: 0.4867 - 3s/epoch - 25ms/step\n",
      "Epoch 45/50\n",
      "122/122 - 3s - loss: 0.4352 - val_loss: 0.4870 - 3s/epoch - 25ms/step\n",
      "Epoch 46/50\n",
      "122/122 - 3s - loss: 0.4357 - val_loss: 0.4877 - 3s/epoch - 25ms/step\n",
      "Epoch 47/50\n",
      "122/122 - 3s - loss: 0.4341 - val_loss: 0.4871 - 3s/epoch - 25ms/step\n",
      "Epoch 48/50\n",
      "122/122 - 3s - loss: 0.4337 - val_loss: 0.4877 - 3s/epoch - 25ms/step\n",
      "Epoch 49/50\n",
      "122/122 - 3s - loss: 0.4342 - val_loss: 0.4889 - 3s/epoch - 25ms/step\n",
      "Epoch 50/50\n",
      "122/122 - 3s - loss: 0.4334 - val_loss: 0.4897 - 3s/epoch - 25ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b38bc78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2243fa13119e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make a prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# invert scaling for forecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minv_yhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4cf12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
